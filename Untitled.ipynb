{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f96364a-116a-421f-965f-7a7b811fb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Training Set Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.50      0.61      3476\n",
      "         1.0       0.63      0.86      0.73      3445\n",
      "\n",
      "    accuracy                           0.68      6921\n",
      "   macro avg       0.71      0.68      0.67      6921\n",
      "weighted avg       0.71      0.68      0.67      6921\n",
      "\n",
      "Training ROC AUC: 0.7674402621500782\n",
      "----- Validation Set Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.49      0.55       480\n",
      "         1.0       0.55      0.69      0.61       442\n",
      "\n",
      "    accuracy                           0.59       922\n",
      "   macro avg       0.59      0.59      0.58       922\n",
      "weighted avg       0.59      0.59      0.58       922\n",
      "\n",
      "Validation ROC AUC: 0.6386783559577677\n",
      "----- Test Set Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.49      0.55       475\n",
      "         1.0       0.56      0.69      0.62       447\n",
      "\n",
      "    accuracy                           0.59       922\n",
      "   macro avg       0.59      0.59      0.58       922\n",
      "weighted avg       0.59      0.59      0.58       922\n",
      "\n",
      "Test Set ROC AUC: 0.6487012834098669\n",
      "Sorted test results by predicted probabilities:\n",
      "     Predicted_Probability  Actual_Profit\n",
      "714               0.614259            1.0\n",
      "713               0.614259            1.0\n",
      "606               0.611248            1.0\n",
      "607               0.611248            0.0\n",
      "36                0.608906            0.0\n",
      "..                     ...            ...\n",
      "433               0.452105            0.0\n",
      "434               0.452105            1.0\n",
      "645               0.452043            0.0\n",
      "644               0.452043            0.0\n",
      "701               0.450267            1.0\n",
      "\n",
      "[922 rows x 2 columns]\n",
      "Top 10 predicted probabilities and actual profits:\n",
      "     Predicted_Probability  Actual_Profit\n",
      "714               0.614259            1.0\n",
      "713               0.614259            1.0\n",
      "606               0.611248            1.0\n",
      "607               0.611248            0.0\n",
      "36                0.608906            0.0\n",
      "35                0.608906            1.0\n",
      "196               0.607829            1.0\n",
      "197               0.607829            0.0\n",
      "702               0.607330            1.0\n",
      "703               0.607330            1.0\n",
      "----- Holdout Set Evaluation -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.46      0.51       211\n",
      "         1.0       0.61      0.70      0.65       250\n",
      "\n",
      "    accuracy                           0.59       461\n",
      "   macro avg       0.59      0.58      0.58       461\n",
      "weighted avg       0.59      0.59      0.59       461\n",
      "\n",
      "Holdout Set ROC AUC: 0.6378293838862559\n",
      "Sorted test results by predicted probabilities:\n",
      "     Predicted_Probability  Actual_Profit\n",
      "79                0.625166            1.0\n",
      "56                0.623147            1.0\n",
      "57                0.623147            1.0\n",
      "22                0.618901            1.0\n",
      "21                0.618901            1.0\n",
      "..                     ...            ...\n",
      "205               0.456062            0.0\n",
      "176               0.455913            1.0\n",
      "191               0.455491            1.0\n",
      "190               0.455491            0.0\n",
      "201               0.454080            1.0\n",
      "\n",
      "[461 rows x 2 columns]\n",
      "Top 10 predicted probabilities and actual profits:\n",
      "     Predicted_Probability  Actual_Profit\n",
      "79                0.625166            1.0\n",
      "56                0.623147            1.0\n",
      "57                0.623147            1.0\n",
      "22                0.618901            1.0\n",
      "21                0.618901            1.0\n",
      "304               0.618364            1.0\n",
      "305               0.618364            1.0\n",
      "231               0.616991            1.0\n",
      "232               0.616991            1.0\n",
      "162               0.615185            1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Load and prepare the dataset\n",
    "def load_and_prepare_data():\n",
    "    train_data = pd.read_csv('train_data(new2).csv')\n",
    "    val_data = pd.read_csv('val_data(new2).csv')\n",
    "    test_data = pd.read_csv('test_data(new2).csv')\n",
    "    holdout_data = pd.read_csv('holdout_data(new2).csv')\n",
    "\n",
    "    train_data['Entry_Date'] = pd.to_datetime(train_data['Entry_Date'])\n",
    "    val_data['Entry_Date'] = pd.to_datetime(val_data['Entry_Date'])\n",
    "    test_data['Entry_Date'] = pd.to_datetime(test_data['Entry_Date'])\n",
    "    holdout_data['Entry_Date'] = pd.to_datetime(holdout_data['Entry_Date'])\n",
    "\n",
    "    train_data = train_data.sort_values(by='Entry_Date')\n",
    "    val_data = val_data.sort_values(by='Entry_Date')\n",
    "    test_data = test_data.sort_values(by='Entry_Date')\n",
    "    holdout_data = holdout_data.sort_values(by='Entry_Date')\n",
    "\n",
    "    train_data.dropna(inplace=True)\n",
    "    val_data.dropna(inplace=True)\n",
    "    test_data.dropna(inplace=True)\n",
    "    holdout_data.dropna(inplace=True)\n",
    "    \n",
    "    return train_data, val_data, test_data, holdout_data\n",
    "\n",
    "# Train the model with provided parameters\n",
    "def train_model(train_data, val_data, params, features, target):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_clf.fit(train_data[features], train_data[target])\n",
    "    \n",
    "    # Apply Platt scaling\n",
    "    calibrated_rf_clf = CalibratedClassifierCV(estimator=rf_clf, method='sigmoid')\n",
    "    calibrated_rf_clf.fit(train_data[features], train_data[target])\n",
    "    \n",
    "    # Evaluate on training set\n",
    "    y_train_pred = calibrated_rf_clf.predict(train_data[features])\n",
    "    y_train_pred_proba = calibrated_rf_clf.predict_proba(train_data[features])[:, 1]\n",
    "    print(\"----- Training Set Evaluation -----\")\n",
    "    print(classification_report(train_data[target], y_train_pred))\n",
    "    roc_auc_train = roc_auc_score(train_data[target], y_train_pred_proba)\n",
    "    print(f\"Training ROC AUC: {roc_auc_train}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = calibrated_rf_clf.predict(val_data[features])\n",
    "    y_val_pred_proba = calibrated_rf_clf.predict_proba(val_data[features])[:, 1]\n",
    "    print(\"----- Validation Set Evaluation -----\")\n",
    "    print(classification_report(val_data[target], y_val_pred))\n",
    "    roc_auc_val = roc_auc_score(val_data[target], y_val_pred_proba)\n",
    "    print(f\"Validation ROC AUC: {roc_auc_val}\")\n",
    "    \n",
    "    return calibrated_rf_clf\n",
    "\n",
    "# Final evaluation on the test set\n",
    "def evaluate_on_test_set(model, test_data, features, target, set_name=\"Test Set\"):\n",
    "    y_test_pred = model.predict(test_data[features])\n",
    "    y_test_pred_proba = model.predict_proba(test_data[features])[:, 1]\n",
    "    print(f\"----- {set_name} Evaluation -----\")\n",
    "    print(classification_report(test_data[target], y_test_pred))\n",
    "    roc_auc_test = roc_auc_score(test_data[target], y_test_pred_proba)\n",
    "    print(f\"{set_name} ROC AUC: {roc_auc_test}\")\n",
    "\n",
    "    # Sort the test results by predicted probabilities\n",
    "    test_results = pd.DataFrame({\n",
    "        'Predicted_Probability': y_test_pred_proba,\n",
    "        'Actual_Profit': test_data[target]\n",
    "    })\n",
    "    sorted_test_results = test_results.sort_values(by='Predicted_Probability', ascending=False)\n",
    "    print(\"Sorted test results by predicted probabilities:\")\n",
    "    print(sorted_test_results)\n",
    "\n",
    "    # Display top 10 predicted probabilities and actual profits\n",
    "    top_n = 10\n",
    "    top_n_results = sorted_test_results.head(top_n)\n",
    "    print(f\"Top {top_n} predicted probabilities and actual profits:\")\n",
    "    print(top_n_results)\n",
    "    \n",
    "    return sorted_test_results\n",
    "\n",
    "train_data, val_data, test_data, holdout_data = load_and_prepare_data()\n",
    "\n",
    "# Set the parameters for the model\n",
    "params = {\n",
    "    'n_estimators': 20,\n",
    "    'max_depth': 20,\n",
    "    'min_samples_split': 50,\n",
    "    'min_samples_leaf': 20\n",
    "}\n",
    "\n",
    "# Define the features and target\n",
    "selected_features = [\n",
    "    'SMA5_At_Entry', 'SMA10_At_Entry', 'EMA5_At_Entry', 'EMA15_At_Entry', 'RSI5_At_Entry', 'RSI10_At_Entry',\n",
    "    'ATR5_At_Entry', 'ATR15_At_Entry', 'Stoch7_K_At_Entry', 'Stoch21_K_At_Entry',\n",
    "    'BB10_High_At_Entry', 'BB10_Low_At_Entry', 'BB10_MAvg_At_Entry',\n",
    "    'BB15_High_At_Entry', 'BB15_Low_At_Entry', 'BB15_MAvg_At_Entry',\n",
    "    'MACD_At_Entry', 'Day_Of_Week_At_Entry',\n",
    "    'ROC14_At_Entry', 'ROC15_At_Entry', 'Open', 'Low', 'High', 'Last'\n",
    "]\n",
    "\n",
    "target = 'Target'\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "calibrated_rf_clf = train_model(train_data, val_data, params, selected_features, target)\n",
    "\n",
    "# Final evaluation on the test set\n",
    "sorted_test_results_test = evaluate_on_test_set(calibrated_rf_clf, test_data, selected_features, target, set_name=\"Test Set\")\n",
    "\n",
    "# Evaluation on the holdout set\n",
    "sorted_test_results_holdout = evaluate_on_test_set(calibrated_rf_clf, holdout_data, selected_features, target, set_name=\"Holdout Set\")\n",
    "\n",
    "# Add predicted confidence to test_data for use in allocation methods\n",
    "test_data['Predicted_Confidence'] = sorted_test_results_test['Predicted_Probability'].values\n",
    "holdout_data['Predicted_Confidence'] = sorted_test_results_holdout['Predicted_Probability'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814b715a-d338-424f-9522-690d0111ab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Statistic: 0.2435049019607843, P-value: 1.7608243387793867e-12\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def ks_test(y_true, y_pred_proba):\n",
    "    # Separate the probabilities by class\n",
    "    positive_proba = y_pred_proba[y_true == 1]\n",
    "    negative_proba = y_pred_proba[y_true == 0]\n",
    "\n",
    "    # Perform the KS test\n",
    "    ks_statistic, p_value = ks_2samp(positive_proba, negative_proba)\n",
    "    print(f\"KS Statistic: {ks_statistic}, P-value: {p_value}\")\n",
    "    \n",
    "    return ks_statistic, p_value\n",
    "\n",
    "# Apply KS test on the validation set\n",
    "ks_stat, p_val = ks_test(val_data[target], calibrated_rf_clf.predict_proba(val_data[selected_features])[:, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
